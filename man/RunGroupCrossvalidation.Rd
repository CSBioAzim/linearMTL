% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv_tree-guided_group_lasso.R
\name{RunGroupCrossvalidation}
\alias{RunGroupCrossvalidation}
\title{Cross-validation wrapper for \code{\link{TreeGuidedGroupLasso}}.}
\usage{
RunGroupCrossvalidation(X = NULL, task.specific.features = list(), Y,
  groups, weights.matrix, lambda.vec, num.folds = 10, num.threads = 1,
  verbose = -1, row.weights = NULL, standardize = TRUE,
  fit.intercept = TRUE, ...)
}
\arguments{
\item{X}{Column centered N by J input matrix of features common to all tasks.}

\item{task.specific.features}{List of features which are specific to
each task. Each entry contains an N by J2 column-centered matrix for one
particular task (where columns are features). List has to be ordered
according to the columns of Y.}

\item{Y}{Column centered N by K output matrix for every task.}

\item{groups}{V by K matrix determining group membership: Task k in group v
iff groups[v,k] == 1 weights.matrix: Numerical matrix where each row is a
numerical vector mapping groups to their weight.}

\item{weights.matrix}{Numerical matrix where each row is a numerical vector
mapping groups to their weight.}

\item{lambda.vec}{Vector of regularization parameters.}

\item{num.folds}{Number of folds.}

\item{num.threads}{Number of threads to use.}

\item{verbose}{(Optional) Integer in {-2, -1, 0,1,2}. verbose = -2: No
output. verbose = -1: Display total elapsed time. verbose = 0: Display
elapsed time for every parameter. verbose = 1: Print summary at the end of
the optimization. verbose = 2: Print progress during optimization.}

\item{row.weights}{(Optional) Use weighted MSE.}

\item{standardize}{(Optional) Default is TRUE. Standardize data (using R
function scale()). Coefficients will be returned on original scale.}

\item{fit.intercept}{(Optional) Default is TRUE. Include intercept.}

\item{...}{Additional parameters passed to
\code{\link{TreeGuidedGroupLasso}}.}
}
\value{
List containing
    \item{cv.results}{data.frame with cross-validation errors for
    different parameters.}
    \item{full.model}{Full model trained on the whole data set.}
}
\description{
Perform k-fold cross-validation to find optimal parameters settings.
}
\seealso{
\code{\link{TreeGuidedGroupLasso}}
}
